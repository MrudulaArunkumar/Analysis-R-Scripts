table(sample1$Condition,sample1$Validity,sample1$CorrectAnswer)
table(sample1$Condition,sample1$Target1,sample1$CorrectAnswer)
setwd ("C:/FSU Jena_PhD/Statistics/Failing at R stats")
hsb = read.csv("hsb.csv")
#to go to the end of the df use function tail
tail(hsb)
wooftibble = tibble(meow=1:10, woof=seq(2,20, by=2))
library(tidyverse)
wooftibble = tibble(meow=1:10, woof=seq(2,20, by=2))
tibble(hsb)
#use tibble to view data with the details about the df
as_tibble(hsb)
filter(hsb, female = 1)
filter(hsb, female == 1)
filter(hsb, female ==1 & ses>0)
hsb_tibble = as.tibble(hsb)
hsb_tibble = as_tibble(hsb)
filter(hsb_tibble, female == 0, schid != 1224)
arrange(hsb_tibble,matach)
arrange(hsb_tibble,mathach)
#by default it is arranging.ifyou want to do it descending then
arrange(hsb_tibble.desc(schid))
#by default it is arranging.ifyou want to do it descending then
arrange(hsb_tibble,desc(schid))
#arrange more variables
arrange(hsb_tibble,desc(schid),mathach)
mutate(hsb_tibble,deviation = mathach-12.74785)
sd(hsb$mathach)
mutate(hsb_tibble,
deviation = mathach - 12.74785,
zscore = deviation/6.878246)
#you can use transmute that can show just the new variables
transmute(hsb_tibble,
deviation = mathach - 12.74785,
zscore = deviation/6.878246)
select(hsb_tibble, mathach, studentid)
select(hsb_tibble, starts_with("s"))
select(hsb_tibble, ends_with("id"))
select(hsb_tibble, contains("a"))
summarise(hsb_tibble, mean_mathach=mean(mathach,na.rm = TRUE))
library(readr)
sample1 <- read_csv("C:/Python/exp1 overshadowing/data/50_overshadowing_2020_Jun_16_1542.csv")
View(sample1)
table(sample1$Condition,sample1$Target1,sample1$CorrectAnswer)
table(sample1$Validity,sample1$Condition,sample1$Saliency)
table(sample1$Validity,sample1$Condition,sample1$Saliency,sample1$Block)
table(sample$ResponseKey.rt)
View(sample1)
table(sample1$ResponseKey.rt)
library(readr)
sample1 <- read_csv("C:/Python/exp1 overshadowing/data/50_overshadowing_2020_Jun_16_1542.csv")
View(sample1)
library(tidyverse)
sample1$RT <- sample1$ResponseKey.rt
sample1$ACC <- sample1$ResponseKey.corr
sample1$Errorrate <- 1 - sample1$ACC
sample1 <- sample1 %>%
filter(Block = "Practice", "ExpfirstLearn")
sample1 <- sample1 %>%
filter(Block == "Practice", "ExpfirstLearn")
sample1 <- sample1 %>%
filter(Block == "Practice" & "ExpfirstLearn")
sample1 <- sample1 %>%
filter(Block == "Practice" && "ExpfirstLearn")
sample1 <- sample1 %>%
filter(Block = "Practice" && "ExpfirstLearn")
sample1 <- sample1 %>%
filter(Block == Practice && ExpfirstLearn)
sample1 <- sample1 %>%
filter(!grepl("Practice", "ExpfirstLearn", Block))
sample1 <- sample1 %>%
filter(!grepl("Practice", "ExpfirstLearn", Block)) %>%
summarise(RT)
sample1 <- sample1 %>%
filter(!grepl("Practice", "ExpfirstLearn", Block)) %>%
mean(RT)
is.na(RT)
sample1 <- sample1 %>%
filter(!grepl("Practice", "ExpfirstLearn", Block)) %>%
mean(sample1$RT)
mean(sample1$RT)
summary(sample1$RT)
summary(sample1$RT)
is.na(RT)
is.na(sample1$RT)
sample1 <- as.data.frame(sample1)
summary(sample1$RT)
View(sample1)
library(readr)
sample1 <- read_csv("C:/Python/exp1 overshadowing/data/50_overshadowing_2020_Jun_16_1542.csv")
View(sample1)
library(tidyverse)
sample1$RT <- sample1$ResponseKey.rt
sample1$ACC <- sample1$ResponseKey.corr
sample1$Errorrate <- 1 - sample1$ACC
sample1 <- sample1 %>%
filter(!grepl("Practice", "ExpfirstLearn", Block))
summary(sample1$RT)
head(sample1$RT)
head(sample1)
tibble(sample1)
sample1$RT <- as.numeric(sample1$ResponseKey.rt)
sample1$RT <- as.numeric(sample1$ResponseKey.rt)
is.na(sample1$RT)
sample1 <- as.numeric(sample1$ResponseKey.rt)
sample1$RT <- sample1$ResponseKey.rt
library(readr)
sample1 <- read_csv("C:/Python/exp1 overshadowing/data/50_overshadowing_2020_Jun_16_1542.csv")
View(sample1)
sample1$RT <- sample1$ResponseKey.rt[0]
sample1 <- separate(sample1$ResponseKey.rt, c("RT_Trials", "RT_secondary"))
library(tidyverse)
sample1 <- separate(sample1$ResponseKey.rt, c("RT_Trials", "RT_secondary"))
sample1 <- separate(sample1$ResponseKey.rt, c("RT_Trials", "RT_secondary"), sep = ',')
sample1$RT <- sample1$ResponseKey.rt[0]
separate(sample1, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ",")
View(sample1)
View(sample1)
sample1 <- separate(sample1, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ",")
View(sample1)
View(sample1)
?gsub
library(readr)
sample1 <- read_csv("C:/Python/exp1 overshadowing/data/50_overshadowing_2020_Jun_16_1542.csv")
View(sample1)
sample1$ResponseKey.rt <- gsub("[]", "", sample1$ResponseKey.rt)
sample1$ResponseKey.rt <- gsub("[[]]", "", sample1$ResponseKey.rt)
sample1 <- separate(sample1, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ",")
sample1$ACC <- sample1$ResponseKey.corr
sample1$Errorrate <- 1 - sample1$ACC
sample1 <- sample1 %>%
filter(!grepl("Practice", "ExpfirstLearn", Block))
summary(sample1$RT)
summary(sample1$RT_Trials)
sample1$RT_Trials <- as.numeric(sample1$RT_Trials)
summary(sample1$RT_Trials)
is.na(sample1$RT_Trials)
View(sample1)
View(sample1)
read.csv("C:/Python/exp1 overshadowing/data/sample1.csv")
Sample <-read.csv("C:/Python/exp1 overshadowing/data/sample1.csv")
Sample <- subset(Sample, Block = NA)
View(Sample)
names(Sample)[1] <- "Block"
Sample <- subset(Sample, Block = NA)
View(Sample)
View(Sample)
Sample <- Sample[Sample$PracRepeat.thisN == NA]
Sample <- Sample[Sample$PracRepeat.thisN = NA]
Sample <- Sample[Sample$PracRepeat.thisN = "NA"]
Sample <- Sample[Sample$PracRepeat.thisN == "NA"]
Sample <- filter(Sample, PracRepeat.thisN == "NA")
View(Sample)
View(Sample)
## Week 3
library(tidyverse)
setwd ("C:/FSU Jena_PhD/Statistics/Failing at R stats")
hsb = read.csv("hsb.csv")
library(tidyverse)
filter(hsb, female ==1 & ses>0)
hsb_tibble = as_tibble(hsb)
filter(hsb_tibble, female == 0, schid != 1224)
by_sex=group_by(hsb_tibble,female)
summarise(by_sex, mean_mathach=mean(mathach,na.rm=TRUE))
by_sch=group_by(hsb_tibble,schid)
summarise(by_sch,count_n(),
mean_mathach=mean(mathach,na.rm=TRUE),
mean_ses=mean(ses,na.rm=TRUE))
summarise(by_sch,count-n(),
mean_mathach=mean(mathach,na.rm=TRUE),
mean_ses=mean(ses,na.rm=TRUE))
summarise(by_sch,count=n(),
mean_mathach=mean(mathach,na.rm=TRUE),
mean_ses=mean(ses,na.rm=TRUE))
filter(schoolsum,count<25)
filter(Schoolsum,count<25)
schoolsum=summarise(by_sch,count=n(),
mean_mathach=mean(mathach,na.rm=TRUE),
mean_ses=mean(ses,na.rm=TRUE))
filter(schoolsum,count<25)
hsb_tibble %>% summarise(maxmath=max(mathach),maxses=max(ses))
newvar = mutate(hsb_tibble,
deviation = mathach-12.74785,
zscore=deviation/6.878246)
#step2
by_sch=group_by(newvar,schid)
#step3
(schoolsum=summarise(by_sch,
count=n(),
mean_mathachz=mean(zscore,na.rm=TRUE)))
#step4
schoolselect =select(schoolfilter,schid,mean_mathach)
#step4
schoolfilter=filter(schoolsum,count>40)
schoolselect =select(schoolfilter,schid,mean_mathach)
schoolselect =select(schoolfilter,schid,mean_mathachz)
#step6
arrange(schoolselect,desc(mean_mathachz))
hsb_tibble %>%
mutate(deviation = mathach-12.74785,
zscore=deviation/6.878246) %>%
group_by(schid) %>%
summarise(count=n(),mean_mathachz=mean(zscore,na.rm=TRUE)) %>%
filter(count>40)%>%
select(schid,mean_mathachz)%>%
arrange(desc(mean_mathachz))
setwd ("C:/FSU Jena_PhD/Statistics/Failing at R stats")
hsb = read.csv("hsb.csv")#can also be read_csv
library(tidyverse)
hsb_tibble = as_tibble(hsb)
table1=tribble(
~ID, ~MidichlorianCount,
"Sidious",21500,
"Revan",16000,
"Mara",12200,
"Anakin",27800,
"Ahsoka",19000)
table2 = tribble(
~ID, ~SandPreference,
"Sidious",30,
"Revan",21,
"Mara",22,
"Anakin",-1000,
"Rey",29)
table2 = tribble(
~ID, ~SandPreference,
"Sidious",30,
"Revan",21,
"Mara",22,
"Anakin",-1000,
"Rey",29)
table3 <- left_join(table1,table2, by = "ID")
table4 <- right_join(table1,table2, by = "ID")
table5<- inner_join(table1,table2, by = "ID")
table6 <- full_join(table1,table2, by = "ID")
nest_join(table1,table2, by = "ID")
View(table3)
semi_join(table1,table2, by = "ID")
dbz1=tribble(
~ID, ~ season, ~PowerLevel,
"Goku", "Saiyan_saga",32000,
"Goku", "Namek_saga",65000,
"Goku", "Frieza_saga",200000000,
"Goku", "Cell_saga", 546494000000,
"Gohan", "Saiyan_saga", 1307,
"Gohan", "Namek_saga",12000,
"Gohan", "Frieza_saga",2600000,
"Gohan", "Cell_saga",900000000000,
"Vegeta", "Saiyan_saga", 28000,
"Vegeta","Namek_saga", 28000,
"Vegeta", "Frieza_saga",3000000,
"Vegeta", "Cell_saga",70834000000,
"Piccolo", "Saiyan_saga", 1480,
"Piccolo","Namek_saga", 30000,
"Piccolo", "Frieza_saga",1600000,
"Piccolo", "Cell_saga",6000000000
)
left_join(db1,dbz2, by = "ID")
left_join(dbz1,dbz2, by = "ID")
dbz2=tribble(
~ID, ~ season, ~KrillinUseful,
"Goku", "Saiyan_saga",100,
"Goku", "Namek_saga",50,
# "Goku", "Frieza_saga",10,
"Goku", "Cell_saga", -1000,
#"Gohan", "Saiyan_saga", 1000,
"Gohan", "Namek_saga",2000,
"Gohan", "Frieza_saga",1000,
"Gohan", "Cell_saga",-1000,
"Vegeta", "Saiyan_saga", 0,
"Vegeta","Namek_saga", 10,
"Vegeta", "Frieza_saga",0,
# "Vegeta", "Cell_saga",-1000,
"Piccolo", "Saiyan_saga", -1000,
"Piccolo","Namek_saga", -1000,
#"Piccolo", "Frieza_saga",-1000,
"Piccolo", "Cell_saga",-1000
)
left_join(dbz1,dbz2, by = "ID")
right_join(dbz1,dbz2, by = "ID")
left_join(dbz1,dbz2, by = c("ID", "Season"))
left_join(dbz1,dbz2, by = c("ID", "season"))
spread(dbz1,season,PowerLevel)
#arranging column order
dbz1_multi=spread(dbz1,season,PowerLevel) %>%
select(ID, Saiyan_saga,Namek_saga,Frieza_saga,Cell_saga)
###### second example #####
spread(dbz2,season,KrillinUseful)
#Getting columns in the order I want
dbz2_multi=spread(dbz2,season,KrillinUseful) %>%
select(ID, Saiyan_saga,Namek_saga,Frieza_saga,Cell_saga)
dbz1_multi
gather(dbz1_multi,"Season","Power",Saiyan_saga:Cell_saga)
gather(dbz1_multi,"Season","Power",2:5)
dbz1_uni <- gather(dbz1_multi,"Season","Power",Saiyan_saga:Cell_saga)
dbz2_uni=gather(dbz2_multi,"Season","Krillan?",Saiyan_saga:Cell_saga)
#Example 1
dbz1_uni
separate(dbz1_uni,Season,c("SeasonName","Saga"),sep="_",remove=FALSE)
separate(dbz1_uni,Season,c("SeasonName","Saga"),sep="_",remove=TRUE)
dbz1_split=separate(dbz1_uni,Season,c("SeasonName","Saga"),sep="_",remove=FALSE)
#unite(data,column,conc,sept="",remove=TRUE)
#unite(data,columns_to_split,new_variable_names,symbol_that_separates,remove?)
#Example 1
dbz1_split
unite(dbz1_split,Season_Saga,SeasonName,Saga,sep="_")
unite(dbz1_split,Season_Saga,SeasonName,Saga,sep="_",remove=FALSE)
multidbz1 <- pivot_wider(fulldbz,
names_from = season,
values_from=c("PowerLevel","KrillinUseful"))
fulldbz=full_join(dbz1,dbz2, by=c("ID","season"))
fulldbz
spread(fulldbz,season,PowerLevel)
spread(fulldbz,season,KrillinUseful)
spread(fulldbz,season,c(PowerLevel,KrillinUseful))
spread(fulldbz,season,c(PowerLevel,KrillinUseful))
spread(fulldbz,season,KrillinUseful)
spread(fulldbz,season,c(PowerLevel,KrillinUseful))
multidbz1 <- pivot_wider(fulldbz,
names_from = season,
values_from=c("PowerLevel","KrillinUseful"))
View(multidbz1)
View(multidbz1)
multidbz1 %>% pivot_longer(-ID,
names_sep="_",
names_to=c(".value","season"),
values_drop_na=FALSE)
library(tidyverse)
#setting up working directory
#home office
dir <- setwd("C:/FSU Jena_PhD/Exp1/Data/Exp1-Prolific")
#setting up working directory
#home office
dir <- setwd("C:/FSU Jena_PhD/Exp1/Data/Exp1-Prolific")
#create a variable containing all csv files and make a list
allresults <- list.files(path = dir, pattern = "*.csv")
Exp1data_list <- lapply(allresults,read_csv)
#transform and combine it all into one df
Exp1data_OL<- do.call(rbind,Exp1data_list)
#transform and combine it all into one df
Exp1data_OL<- do.call(rbind,Exp1data_list)
#setting up working directory
setwd("C:/FSU Jena_PhD/Exp1/Analysis")
#loading the combined datafile
Exp1data_OL <- read.csv("C:/FSU Jena_PhD/Exp1/Data/Exp1-Prolific/Exp1data_online_fullset.csv")
#loading the necessary libraries
library(tidyverse)
library(ez)
library(schoRsch)
library(lme4)
library(nlme)
library(data.table)
library(knitr)
library(pander)
#clearing up workspace
rm(list=ls())
#setting up working directory
setwd("C:/FSU Jena_PhD/Exp1/Analysis")
#loading the combined datafile
Exp1data_OL <- read.csv("C:/FSU Jena_PhD/Exp1/Data/Exp1-Prolific/Exp1data_online_fullset.csv")
Exp1data_OL <- Exp1data_OL %>%
select(-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisIndex,-Attention.ran,
-id, -session, -researcher, -InstRep.thisRepN,-InstRep.thisIndex,-InstRep.thisN, -InstRep.thisTrialN,
-PracRepeat.thisRepN,-PracRepeat.thisIndex,-PracRepeat.thisN, -PracRepeat.thisTrialN,
-prctrials.thisIndex,-prctrials.thisRepN,-prctrials.thisTrialN,-prctrials.ran,
-firstlearntrials.thisN,-firstlearntrials.thisRepN,-firstlearntrials.thisTrialN,-firstlearntrials.ran,-firstlearntrials.thisIndex,
-afterpause.keys,-blocks.thisRepN,-blocks.thisTrialN,-blocks.thisTrialN,-blocks.thisIndex,-blocks.ran,
)
#Splitting up the RT column to be able to evaluate the RTs
Exp1data_OL <- separate(Exp1data_OL, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ",")
#removing the square bracket and changing from string to numeric
Exp1data_OL$RT_Trials <- Exp1data_OL$RT_Trials %>%
str_replace_all("\\[|\\]", "")%>%
as.numeric(Exp1data_OL$RT_Trials)
View(Exp1data_OL)
#removing the first column named x
Exp1data_OL <- subset(Exp1data_OL, select = -c(X))
View(Exp1data_OL)
Exp1data_OL$ACC_Trials <- Exp1data_OL$ResponseKey.corr
Exp1data_OL$ErrorRate <- 1 - Exp1data_OL$ACC_Trials
#removing practice trial and attention block
Exp1data_OL <- [!grepl("Practice", Exp1data_OL$Condition)]
#removing practice trial and attention block
Exp1data_OL <- [!grepl("Practice", Exp1data_OL$Condition),]
#removing practice trial and attention block
Exp1data_OL <- Exp1data_OL[!grepl("Practice", Exp1data_OL$Condition),]
View(Exp1data_OL)
View(Exp1data_OL)
#removing practice trial and attention block
Exp1data_OL <- Exp1data_OL[!grepl("Practice", Exp1data_OL$Block),]
Exp1data_OL <- Exp1data_OL[!grepl(NA, Exp1data_OL$Block),]
Exp1data_OL <- Exp1data_OL[!grepl("NA", Exp1data_OL$Block),]
#clearing up workspace
rm(list=ls())
#setting up working directory
setwd("C:/FSU Jena_PhD/Exp1/Analysis")
#loading the combined datafile
Exp1data_OL <- read.csv("C:/FSU Jena_PhD/Exp1/Data/Exp1-Prolific/Exp1data_online_fullset.csv")
Exp1data_OL <- Exp1data_OL %>%
select(-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisIndex,-Attention.ran,
-id, -session, -researcher, -InstRep.thisRepN,-InstRep.thisIndex,-InstRep.thisN, -InstRep.thisTrialN,
-PracRepeat.thisRepN,-PracRepeat.thisIndex,-PracRepeat.thisN, -PracRepeat.thisTrialN,
-prctrials.thisIndex,-prctrials.thisRepN,-prctrials.thisTrialN,-prctrials.ran,
-firstlearntrials.thisN,-firstlearntrials.thisRepN,-firstlearntrials.thisTrialN,-firstlearntrials.ran,-firstlearntrials.thisIndex,
-afterpause.keys,-blocks.thisRepN,-blocks.thisTrialN,-blocks.thisTrialN,-blocks.thisIndex,-blocks.ran,
)
#removing the first column named x
Exp1data_OL <- subset(Exp1data_OL, select = -c(X))
#Splitting up the RT column to be able to evaluate the RTs
Exp1data_OL <- separate(Exp1data_OL, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ",")
#removing the square bracket and changing from string to numeric
Exp1data_OL$RT_Trials <- Exp1data_OL$RT_Trials %>%
str_replace_all("\\[|\\]", "")%>%
as.numeric(Exp1data_OL$RT_Trials)
Exp1data_OL$ACC_Trials <- Exp1data_OL$ResponseKey.corr
#new columns for error rate
Exp1data_OL$ErrorRate <- 1 - Exp1data_OL$ACC_Trials
#removing practice trial and attention block
Exp1data_OL <- Exp1data_OL[!grepl("Practice", Exp1data_OL$Block),]
View(Exp1data_OL)
View(Exp1data_OL)
Exp1data_OL <- Exp1data_OL%>%
select(-ResponseKey_p.keys,-ResponseKey_p.corr,-ResponseKey_p.rt,-Prac_start.keys,-Prac_start.rt,-pracend.keys,-pracend.rt)
View(Exp1data_OL)
#removing attention check
Exp1data_OL<-Exp1data_OL%>%
filter(!(Solution %in% c("l", "d")))
View(Exp1data_OL)
#clearing up workspace
rm(list=ls())
#setting up working directory
setwd("C:/FSU Jena_PhD/Exp1/Analysis")
#loading the combined datafile
Exp1data_OL <- read.csv("C:/FSU Jena_PhD/Exp1/Data/Exp1-Prolific/Exp1data_online_fullset.csv")
Exp1data_OL <- Exp1data_OL %>%
select(-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisIndex,-Attention.ran,
-id, -session, -researcher, -InstRep.thisRepN,-InstRep.thisIndex,-InstRep.thisN, -InstRep.thisTrialN,
-PracRepeat.thisRepN,-PracRepeat.thisIndex,-PracRepeat.thisN, -PracRepeat.thisTrialN,
-prctrials.thisIndex,-prctrials.thisRepN,-prctrials.thisTrialN,-prctrials.ran,
-firstlearntrials.thisN,-firstlearntrials.thisRepN,-firstlearntrials.thisTrialN,-firstlearntrials.ran,-firstlearntrials.thisIndex,
-afterpause.keys,-blocks.thisRepN,-blocks.thisTrialN,-blocks.thisTrialN,-blocks.thisIndex,-blocks.ran,
)
#removing the first column named x
Exp1data_OL <- subset(Exp1data_OL, select = -c(X))
#Splitting up the RT column to be able to evaluate the RTs
Exp1data_OL <- separate(Exp1data_OL, col = ResponseKey.rt, into = c("RT_Trials", "RT_secondary"), sep = ",")
#removing the square bracket and changing from string to numeric
Exp1data_OL$RT_Trials <- Exp1data_OL$RT_Trials %>%
str_replace_all("\\[|\\]", "")%>%
as.numeric(Exp1data_OL$RT_Trials)
#making sure screenbg is entered in every cell
Exp1data_OL <- Exp1data_OL%>%group_by(participant)%>%fill(Screen_bg,.direction = "down")
View(Exp1data_OL)
View(Exp1data_OL)
Exp1data_OL$ACC_Trials <- Exp1data_OL$ResponseKey.corr
#new columns for error rate
Exp1data_OL$ErrorRate <- 1 - Exp1data_OL$ACC_Trials
#removing practice trial and attention block
Exp1data_OL <- Exp1data_OL[!grepl("Practice", Exp1data_OL$Block),]
Exp1data_OL <- Exp1data_OL%>%
select(-ResponseKey_p.keys,-ResponseKey_p.corr,-ResponseKey_p.rt,-Prac_start.keys,-Prac_start.rt,-pracend.keys,-pracend.rt)
#removing attention check
Exp1data_OL<-Exp1data_OL%>%
filter(!(Solution %in% c("l", "d")))
View(Exp1data_OL)
View(Exp1data_OL)
#Making sure Experiment unneccessary columns are removed
Exp1data_OL<-Exp1data_OL%>%
select(-InstRep.ran,-consentkey.keys,-consentkey.rt,-beginexp.keys,-beginexp.rt,-checkresp.corr,-checkresp.keys,-checkresp.rt,-Attention.thisN,-Question,-Solution,-gotoPrac.keys,-gotoPrac.rt,-PracRepeat.ran,-prctrials.thisN,-afterpause.rt,-blocks.thisN)
View(Exp1data_OL)
Exp1data_OL<- Exp1data_OL%>%drop_na(RT_Trials)
write.csv(Exp1data_OL, file = "Exp1data_Online_cleaned.csv")
pander(summary(Exp1data$RT_Trial), style = 'rmarkdown', caption = "Summary of RT")
pander(summary(Exp1data_OL$RT_Trials), style = 'rmarkdown', caption = "Summary of RT")
pander(table(Exp1data_OL$ACC_Trials), style = 'rmarkdown', caption = "Number of correct and Incorrect trials")
pander(round(table(Exp1data_OL$ACC_Trials)/nrow(Exp1data_OL)*100, digits = 3), style = 'rmarkdown', caption = "Percentage of errors")
#removing RT values for the incorrect trials
Exp1data_OL$RT_Trials[Exp1data_OL$ACC_Trials==0] <- NA
#mean RT for correct trials
pander(summary(Exp1data_OL$RT_Trial), style = 'rmarkdown', caption = "RT summary after removing incorrectTrials")
#mean RT for correct trials
pander(summary(Exp1data_OL$RT_Trials), style = 'rmarkdown', caption = "RT summary after removing incorrectTrials")
#identifying the outliers and farouts at individual level
Exp1data_OL <- ddply(Exp1data_OL, .(participant), computeTukeys)
#loading the necessary libraries
library(tidyverse)
library(ez)
library(schoRsch)
library(lme4)
library(nlme)
library(data.table)
library(knitr)
library(pander)
library(plyr)
#identifying the outliers and farouts at individual level
Exp1data_OL <- ddply(Exp1data_OL, .(participant), computeTukeys)
#creating function to remove the outliers and farouts
computeTukeys <- function(x){
P25 <- quantile(x$RT, .25, na.rm = TRUE, type = 6) #type = 6 -> nimmt SPSS
P75 <- quantile(x$RT, .75, na.rm = TRUE, type = 6)
x$Outlier <- P75 + 1.5*(P75 - P25)
x$Farouts <- P75 + 3.0*(P75 - P25)
return(x)
}
#identifying the outliers and farouts at individual level
Exp1data_OL <- ddply(Exp1data_OL, .(participant), computeTukeys)
View(Exp1data_OL)
#identifying the outliers and farouts at individual level
Exp1data_OL <- ddply(Exp1data_OL, .(Subject), computeTukeys)
#identifying the outliers and farouts at individual level
Exp1data_OL <- ddply(Exp1data_OL, .(participant), computeTukeys)
View(Exp1data_OL)
